In order to participate to this first edition and to deliver results in a very short time, we made quite strong assumptions and some shortcomings.

Our strategy relies on the detection of the Table of Content (ToC). A simple fallback strategy based on the whole content analysis is used when no ToC pages are detected.

In previous INEX Book Structure Extraction Competitions, we used to consider only the whole document to extract the structure \cite{10.1007/978-3-642-14556-8_18,DBLP:conf/inex/GiguetL10,Giguet2009}.

Taking into account the whole content of the document has many advantages. First, it allows to handle documents without ToC. Second, it permits to extract titles that are not included in the ToC, such as lower-level titles or preliminary titles. Thus, it reflects the real structure of the document. 

Third, and not the least, it avoids having to manage or to process erroneous ToCs. Indeed, the ToC of a document may not be synchronized with the actual version of the document when the author forget to update it. It may also contain entries that are not titles, for instance a paragraph incorrectly labelled as a title, or wrong page numbers. Those cases are not rare. 

Although these issues are well known and plead in favor of an extraction from the whole content, it is interesting to work with a different approach. Thus we choose to locate ToC pages, to extract their content, and to submit the result as the document structure. Our expectations is to have a good precision but a low recall due to missing or incomplete ToCs.

\subsubsection{Technical assumptions}

The experiment is conducted from PDF documents to ensure the control of
the entire process. The document content is extracted using the \texttt{pdf2xml} command \cite{Dejean:2007}.

We assume that the PDF reports are automatically generated by the PDF driver of a word processor. Thus, we do not check if the document is a scanned document or if it is the output of an OCR application. 

Consequently, we do not consider possible trapezoid or parallelogram distortion, page rotation or curved lines. This assumption simplifies the initial stages: baselines are inferred from the coordinates on the x-axis; left, right and centered alignments are inferred from the coordinates on the y-axis.

We also assume that PDF drivers serialize the content of a page area by area, depending on the page layout. A content area corresponds to a page subdivision such as a column, a header, a footer, or a floating table or figure. 

When a content area is processed, we assume that characters and lines are serialized in reading order, so that there is no ordering problem to consider. Thus, when parsing a page, we expect to find the ToC entries serialized in reading order, and we expect to find the different parts of each ToC entry serialized in reading order.

However, content areas are represented neither in the PDF structure nor in the \texttt{pdf2xml} output. Content area are implicitly inferred by the cognitive skills of the reader. Moreover content areas can be serialized in many ways in the PDF. For instance, header and footer areas can be serialized before the document body area. The boundary delimitation of content areas inside a page is one of the main challenges. 

Bounding the ToC areas over pages is not straight due to the absence of marks that separate them from other adjacent areas. In our process, positional information of headers and footers are inferred from the document structure in order to help the boundary delimitation of ToC areas. Taking into account the consistency of the styles within the ToC, and the style contrast with other parts should also help the delimitation.

We point out that there is no concept of ``word" or ``number" or ``token" in PDF. In order to ease the processing, \texttt{pdf2xml} introduces the concept of ``token", a computational unit based on character spacing. In practice, output tokens correspond to words or numbers, what we can expect, but they can also correspond to a composition of several interpretable unit (e.g., ``Introduction....5" or a breakdown of an interpretable unit (e.g., ``C" ``O" ``N" ``T" ``E" ``N" ``T" ).

\subsubsection{Locating the ToC pages}

The ToC is located in the first pages of the document. It can spread over a limited number of contiguous pages. In the training set, we observed in practice up to three contiguous pages. 

While observing various ToCs, it appears that few properties are common to all ToCs over the collection. Some ToCs have a title, others don't have it. Some ToCs have section numbering, others don't have it.

One formal property is common to all ToCs we observed in the corpus:
the page numbers of a ToC are \emph{right-aligned} and form an increasing sequence of integers.

These characteristics are fully exploited in the core of our ToC identification process: we consider the pages of the first third of the document as a search space. Then we select the first right-aligned sequence of lines ending by an integer and that may spread over contiguous pages. We do not have to bound the expected number of ToC pages.

\subsubsection{Building ToC entries}

A ToC Entry is made of several parts, namely an optional level number, the title, an optional leader line (i.e., dotted line), and the page number. A regular expression is enough to capture the different part of the expected ToC entry.

This process must be applied with care since there is a significant risk of confusion between two cases: 
\begin{itemize}
    \item long titles may spread over multiple lines, up to two lines in the corpus,
    \item major headings may not be associated to page numbers. Their page number is implicit and usually corresponds to the page number of the following subheading. For instance, when the title of a chapter is not specified in a ToC, its page number is the same as the page number of its first section.
\end{itemize} 

Styling and span information helps managing these cases.

Leader lines are optional and may not be present on all ToC entries, in particular on major headings.  While leader lines ease the association between titles and page number when title is short or line spacing is thin, larger line spacing, eventually combined to larger font-sizes, can be enough to ease the association for the reader.

\subsubsection{Inferring the Hierarchy}

A ToC is a hierarchical structure. From a computational point of view, it can be seen as the result of a preorder depth-first tree traversal. In practice, it is not the case since we deal with natural language, not computational structure: all the titles do not have to be mentioned. It is the case for lower-level subheadings which could significantly burden the synthetic overview. It is also the case for the main title, or for unnamed parts, such as preliminaries, which are defined by their position and may be considered as minor parts.

A combination of contrastive effects usually reflects the hierarchy:
\begin{itemize}
    \item larger \emph{line-spacing} can be used to highlight major headings ;
    \item positive \emph{indentation} can be used to indicate lower-level subheadings;
    \item \emph{formatting character effects} such as bold, italic, character case and font-size can be used: smaller font-sizes or lower case for lower-level subheadings; bold or uppercase for higher-level headings;
    \item \emph{numbering character sets}: uppercase letters (e.g., A, B, C, I, II)  are more often used for numbering higher-level headings while lowercase letters (e.g., a, b, c, i, ii, iii, $\alpha$, $\beta$, $\gamma$) are used for lower-level subheading;
    \item \emph{multi-level numbering structure}: subheading numbering (e.g., a, b, c) can be prefixed by parent numbering (e.g., A.2.a, A.2.b, A.2.c). The numbering of major parts, such as chapter (e.g., A), may not be prefixed in subheading multi-level number (e.g., 2.a, 2.b, 2.c) and may remain implicit.
\end{itemize}
 
Heading numbering may be prefixed by a functional term, such as Appendix, Chapter, Article, etc. It has to be handled. No specific list of terms has to be build. The term is repeated at the beginning of several ToC entries, before the heading number: it is enough to handle it.

In our process, the computation of the hierarchical structure is based on the combination of subheading indentation and multi-level numbering structure of ToC entries.

\subsubsection{Results and discussion}

The preliminary results of our system \texttt{Daniel} on the test set are given in table \ref{res:toc}.   

\begin{table}
\begin{tabular}{l|l|r}
     & Run & F-measure\\\hline
\texttt{Daniel}  & 1 &      42.72\\\hline
\texttt{IHSMarkit} & 1 &   39.41
\end{tabular}
\caption{Results for the ToC Generation Task on the test set}
\label{res:toc}
\end{table}

Due to lack of time for implementation, we only handled ToC located on one-column page layout, which is the most common case for this kind of document. We did not handle the difference of page format for odd and even pages. Simple improvements can be done to cover these two cases.

As said at the beginning of this section the main improvements would come from taking into account the whole content of the document. We did not have enough time to handle it properly. It would allow the handling of documents without ToC and would permit the extraction of titles that are not included in the ToC. It would be particularly useful for these financial documents where fine-grain subdivisions are present but not represented in the ToC.
